{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scripts.modelling import transform, invert_transform, root_mean_squared_error, mean_absolute_error, model_wrap\n",
    "from scipy.signal import correlate\n",
    "from scipy.fft import fft\n",
    "\n",
    "def split_data(data, window_size=15):\n",
    "    x = []\n",
    "    y = []\n",
    "    start = 0\n",
    "    end = start + window_size\n",
    "\n",
    "    while end < data.shape[0]:\n",
    "        x.append(data.iloc[start:end, 0:4])\n",
    "        y.append(data.iloc[end, [0, 3]])\n",
    "\n",
    "        start = end\n",
    "        end = start + window_size\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    split = int(x.shape[0]*0.7)\n",
    "\n",
    "    return x[0:split, :, :], y[0:split], x[split:, :, :], y[split:]\n",
    "\n",
    "def feature_extractor(data):\n",
    "    res = np.zeros(shape=(data.shape[0], 2))\n",
    "\n",
    "    for row in range(data.shape[0]):\n",
    "        segment = data[row, :, 3]\n",
    "        low = np.min(segment)\n",
    "        high = np.max(segment)\n",
    "\n",
    "        res[row, 0] = (segment[len(segment)-1] - low)/(high-low)*100\n",
    "        res[row, 1] = (segment[len(segment)-1]-segment[0])/(15*60)\n",
    "\n",
    "    return res\n",
    "\n",
    "# Sinusoidal positional encoding, things more close in space have a similar frequency\n",
    "def positional_encoding(seq_len, d_model):\n",
    "    position = np.expand_dims(np.arange(seq_len), 1)  # Shape: (seq_len, 1)\n",
    "    div_term = (10000**(np.arange(0, d_model, 2)/d_model))\n",
    "\n",
    "    pos_enc = np.zeros((seq_len, d_model))\n",
    "    pos_enc[:, 0::2] = np.sin(position * div_term)  # Apply sine to even indices\n",
    "    pos_enc[:, 1::2] = np.cos(position * div_term)  # Apply cosine to odd indices\n",
    "\n",
    "    return tf.convert_to_tensor(pos_enc, dtype=tf.float32)\n",
    "\n",
    "# Positional embedding layers\n",
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pos_encoding = positional_encoding(length=15, depth=d_model)\n",
    "\n",
    "    # Add encodings to values\n",
    "    def call(self, x):\n",
    "        x = x + self.pos_encoding\n",
    "        return x\n",
    "    \n",
    "# Standard self attention layers\n",
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "    \n",
    "    # Do self attention -> add -> norm\n",
    "    def call(self, x):\n",
    "        attn_outputs = self.mha(query=x, key=x, value=x)\n",
    "        x = self.add([x, attn_outputs])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def autocorr(x):\n",
    "    var = np.var(x)\n",
    "    x = x-np.mean(x)\n",
    "    result = correlate(x, x, mode='full', method='auto')\n",
    "    result = result[result.size//2:]\n",
    "    return result/(var*np.arange(len(x), 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polygon import RESTClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "client = RESTClient(api_key=api_key)\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "last_year = (datetime.today() - pd.DateOffset(years=2)).strftime('%Y-%m-%d')\n",
    "\n",
    "ticker = 'AMD'\n",
    "resp = pd.DataFrame(client.get_aggs(ticker, multiplier=1, timespan='minute', from_=last_year, to=today, limit=120000))\n",
    "resp = resp.drop(columns=['timestamp', 'otc'])\n",
    "#resp.to_csv(f'{ticker}_{today}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "news_articles = client.list_ticker_news(\n",
    "\t\"AAPL\", \n",
    "\tparams={\"published_utc.gte\": today}, \n",
    "\torder=\"desc\", \n",
    "\tlimit=1000\n",
    "\t)\n",
    "\n",
    "for article in news_articles:\n",
    "    print(f\"{article.title} [Insights: {article.insights}]\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'AAPL_2024-12-17.csv')\n",
    "x_train, y_train, x_test, y_test = split_data(data)\n",
    "\n",
    "encoding = positional_encoding(15, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trend forecasting\n",
    "\n",
    "- 1. Autocorrelation\n",
    "> Determine general direction of the stock's open over time period\n",
    "> Potential extra model input\n",
    "\n",
    "- 2. Velocity and Acceleration(?) of stock\n",
    "> Calculate total window velocity (price delta/time delta)\n",
    "> Calculate point to point velcoity \n",
    "\n",
    "- 3. Model Changes\n",
    "> Swap to transformer\n",
    "> Use more inputs\n",
    "> Batch predict stocks of the same general industry (semiconductors: AAPL, AMD, NVDA, SSNLF, TSMC)\n",
    "> Incorporate sentiment analysis into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Autocorrelation of open and close\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "i = 2\n",
    "autocorr_open = autocorr(x_train[i, :, 0])\n",
    "autocorr_close = autocorr(x_train[i, :, 0])\n",
    "\n",
    "ax[0].plot(x_train[i, :, 0])\n",
    "ax[1].plot(autocorr_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_wrap(model=NN(x_train.shape[1]), transform=transform, invert_transform=invert_transform)\n",
    "model.model.summary()\n",
    "\n",
    "loss = keras.losses.MeanSquaredError()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.fit(x_train, y_train, loss=loss, optimizer=optimizer, epochs=100)\n",
    "model.model.save('LSTM_feedend.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_train, y_train)\n",
    "\n",
    "res_df = pd.DataFrame({'Open MAE': mean_absolute_error(y_train[:, 0], y_pred[:, 0]),\n",
    "                       'Close MAE': mean_absolute_error(y_train[:, 1], y_pred[:, 1])}, index=[0])\n",
    "\n",
    "display(res_df)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].scatter(y_train[:, 0], y_pred[:, 0])\n",
    "ax[1].scatter(y_train[:, 1], y_pred[:, 1])\n",
    "ax[0].plot(y_train[:, 0], y_train[:, 0], c='r')\n",
    "ax[1].plot(y_train[:, 1], y_train[:, 1], c='r')\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].scatter(y_train[:, 0]-y_pred[:, 0], y_train[:, 0])\n",
    "ax[1].scatter(y_train[:, 1]-y_pred[:, 1], y_train[:, 1])\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].plot(y_train[:, 0])\n",
    "ax[0].plot(y_pred[:, 0])\n",
    "ax[1].plot(y_train[:, 1])\n",
    "ax[1].plot(y_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test, y_test)\n",
    "display(y_test.shape, y_pred.shape)\n",
    "\n",
    "res_df = pd.DataFrame({'Open MAE': mean_absolute_error(y_test[:, 0], y_pred[:, 0]),\n",
    "                       'Close MAE': mean_absolute_error(y_test[:, 1], y_pred[:, 1])}, index=[0])\n",
    "\n",
    "display(res_df)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].scatter(y_test[:, 0], y_pred[:, 0])\n",
    "ax[1].scatter(y_test[:, 1], y_pred[:, 1])\n",
    "ax[0].plot(y_test[:, 0], y_test[:, 0], c='r')\n",
    "ax[1].plot(y_test[:, 1], y_test[:, 1], c='r')\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].scatter(y_test[:, 0]-y_pred[:, 0], y_test[:, 0])\n",
    "ax[1].scatter(y_test[:, 1]-y_pred[:, 1], y_test[:, 1])\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].plot(y_test[:, 0])\n",
    "ax[0].plot(y_pred[:, 0])\n",
    "ax[1].plot(y_test[:, 1])\n",
    "ax[1].plot(y_pred[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
